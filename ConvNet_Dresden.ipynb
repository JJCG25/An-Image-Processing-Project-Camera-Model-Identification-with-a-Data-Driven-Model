{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Clasificación de Cámaras Mediante el Análisis del Ruido del Sensor en Imágenes Digitales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Librerías*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T17:17:01.658926Z",
     "iopub.status.busy": "2025-05-26T17:17:01.658416Z",
     "iopub.status.idle": "2025-05-26T17:17:07.026728Z",
     "shell.execute_reply": "2025-05-26T17:17:07.025903Z",
     "shell.execute_reply.started": "2025-05-26T17:17:01.658901Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Procesamiento de las imagenes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:10:56.896916Z",
     "iopub.status.busy": "2025-05-25T22:10:56.895758Z",
     "iopub.status.idle": "2025-05-25T22:10:56.901233Z",
     "shell.execute_reply": "2025-05-25T22:10:56.900186Z",
     "shell.execute_reply.started": "2025-05-25T22:10:56.896884Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"Dresden_Exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:05:24.294152Z",
     "iopub.status.busy": "2025-05-25T22:05:24.293834Z",
     "iopub.status.idle": "2025-05-25T22:05:24.330618Z",
     "shell.execute_reply": "2025-05-25T22:05:24.329428Z",
     "shell.execute_reply.started": "2025-05-25T22:05:24.294131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "camera_dirs = sorted([d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))])\n",
    "\n",
    "print(f\"{'Carpeta':40} | Imágenes\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for folder in camera_dirs:\n",
    "    folder_path = os.path.join(DATA_DIR, folder)\n",
    "    files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    print(f\"{folder:40} | {len(files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:05:14.032208Z",
     "iopub.status.busy": "2025-05-25T22:05:14.031358Z",
     "iopub.status.idle": "2025-05-25T22:05:14.522331Z",
     "shell.execute_reply": "2025-05-25T22:05:14.521228Z",
     "shell.execute_reply.started": "2025-05-25T22:05:14.032173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "folder_names = []\n",
    "image_counts = []\n",
    "\n",
    "for folder in camera_dirs:\n",
    "    folder_path = os.path.join(DATA_DIR, folder)\n",
    "    files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    folder_names.append(folder)\n",
    "    image_counts.append(len(files))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(folder_names, image_counts)\n",
    "plt.xlabel(\"Cantidad de imágenes\")\n",
    "plt.title(\"Imágenes por carpeta (modelo de cámara)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Extracción de parches*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T20:44:28.557806Z",
     "iopub.status.busy": "2025-05-25T20:44:28.557378Z",
     "iopub.status.idle": "2025-05-25T21:21:49.913082Z",
     "shell.execute_reply": "2025-05-25T21:21:49.910406Z",
     "shell.execute_reply.started": "2025-05-25T20:44:28.557777Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"patches_by_class_batch\"\n",
    "PATCH_SIZE = 48\n",
    "PATCHES_PER_IMAGE = 25\n",
    "BATCH_SIZE = 500\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def extract_random_patches(img, num_patches=10, patch_size=48):\n",
    "    patches = []\n",
    "    h, w, _ = img.shape\n",
    "    for _ in range(num_patches):\n",
    "        y = np.random.randint(0, h - patch_size)\n",
    "        x = np.random.randint(0, w - patch_size)\n",
    "        patch = img[y:y+patch_size, x:x+patch_size]\n",
    "        patches.append(patch)\n",
    "    return patches\n",
    "\n",
    "for camera_model in tqdm(os.listdir(DATA_DIR)):\n",
    "    model_dir = os.path.join(DATA_DIR, camera_model)\n",
    "    if not os.path.isdir(model_dir):\n",
    "        continue\n",
    "\n",
    "    image_files = os.listdir(model_dir)\n",
    "    num_batches = (len(image_files) + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        start = batch_idx * BATCH_SIZE\n",
    "        end = min((batch_idx + 1) * BATCH_SIZE, len(image_files))\n",
    "        batch_files = image_files[start:end]\n",
    "\n",
    "        patches = []\n",
    "        labels = []\n",
    "\n",
    "        for image_file in batch_files:\n",
    "            img_path = os.path.join(model_dir, image_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None or img.shape[0] < PATCH_SIZE or img.shape[1] < PATCH_SIZE:\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            extracted = extract_random_patches(img, PATCHES_PER_IMAGE, PATCH_SIZE)\n",
    "            patches.extend(extracted)\n",
    "            labels.extend([camera_model] * len(extracted))\n",
    "\n",
    "        if patches:\n",
    "            patches_array = np.array(patches)\n",
    "            labels_array = np.array(labels)\n",
    "            np.save(os.path.join(OUTPUT_DIR, f\"{camera_model}_patches_batch{batch_idx}.npy\"), patches_array)\n",
    "            np.save(os.path.join(OUTPUT_DIR, f\"{camera_model}_labels_batch{batch_idx}.npy\"), labels_array)\n",
    "            print(f\"✅ Guardado: {camera_model} - batch {batch_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T21:30:50.267792Z",
     "iopub.status.busy": "2025-05-25T21:30:50.266828Z",
     "iopub.status.idle": "2025-05-25T21:31:06.837507Z",
     "shell.execute_reply": "2025-05-25T21:31:06.836415Z",
     "shell.execute_reply.started": "2025-05-25T21:30:50.267750Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Aqui se juntan todos los parches por batches para poder hacer la division del dataset 70-30, toco asi porque crear los parches para todo\n",
    "# el conjunto de fotos de un solo sensor no se podia (Se quedaba sin memoria RAM)\n",
    "\n",
    "PATCHES_DIR = \"patches_by_class_batch\"\n",
    "\n",
    "all_patches = []\n",
    "all_labels = []\n",
    "\n",
    "# Solo buscar archivos que son batches de parches\n",
    "for fname in sorted(os.listdir(PATCHES_DIR)):\n",
    "    if \"_patches_batch\" in fname and fname.endswith(\".npy\"):\n",
    "        base_name = fname.replace(\"_patches_batch\", \"_labels_batch\")\n",
    "        patches_path = os.path.join(PATCHES_DIR, fname)\n",
    "        labels_path = os.path.join(PATCHES_DIR, base_name)\n",
    "\n",
    "        # Verificar que existan ambos archivos\n",
    "        if not os.path.exists(labels_path):\n",
    "            print(f\"Falta el archivo de etiquetas para: {fname}\")\n",
    "            continue\n",
    "\n",
    "        # Cargar parches y etiquetas\n",
    "        patches = np.load(patches_path)\n",
    "        labels = np.load(labels_path)\n",
    "\n",
    "        all_patches.append(patches)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "# Concatenar todos los arrays\n",
    "X = np.concatenate(all_patches, axis=0)\n",
    "y = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "print(f\"Parches totales: {X.shape}\")\n",
    "print(f\"Etiquetas totales: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T21:31:59.141081Z",
     "iopub.status.busy": "2025-05-25T21:31:59.140279Z",
     "iopub.status.idle": "2025-05-25T21:31:59.513871Z",
     "shell.execute_reply": "2025-05-25T21:31:59.513037Z",
     "shell.execute_reply.started": "2025-05-25T21:31:59.141049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Asignacion de clases, le asigna una clase a cada sensor, en la siguiente celda puse el print para ver como queda\n",
    "\n",
    "classes = sorted(np.unique(y))\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "y_idx = np.array([class_to_idx[label] for label in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:28:32.223386Z",
     "iopub.status.busy": "2025-05-25T22:28:32.223047Z",
     "iopub.status.idle": "2025-05-25T22:28:32.228656Z",
     "shell.execute_reply": "2025-05-25T22:28:32.227577Z",
     "shell.execute_reply.started": "2025-05-25T22:28:32.223362Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T21:32:26.966052Z",
     "iopub.status.busy": "2025-05-25T21:32:26.965663Z",
     "iopub.status.idle": "2025-05-25T21:32:28.190735Z",
     "shell.execute_reply": "2025-05-25T21:32:28.189975Z",
     "shell.execute_reply.started": "2025-05-25T21:32:26.966025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Split 70-30\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_idx, test_size=0.3, stratify=y_idx, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T21:33:36.833771Z",
     "iopub.status.busy": "2025-05-25T21:33:36.832993Z",
     "iopub.status.idle": "2025-05-25T21:33:41.625966Z",
     "shell.execute_reply": "2025-05-25T21:33:41.624884Z",
     "shell.execute_reply.started": "2025-05-25T21:33:36.833735Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Aqui se guardan los splits para no hacer lo mismo cada vez que entremos al notebook\n",
    "\n",
    "os.makedirs(\"final_dataset\", exist_ok=True)\n",
    "np.save(\"final_dataset/X_train.npy\", X_train)\n",
    "np.save(\"final_dataset/X_test.npy\", X_test)\n",
    "np.save(\"final_dataset/y_train.npy\", y_train)\n",
    "np.save(\"final_dataset/y_test.npy\", y_test)\n",
    "np.save(\"final_dataset/class_to_idx.npy\", class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T17:17:20.490586Z",
     "iopub.status.busy": "2025-05-26T17:17:20.489626Z",
     "iopub.status.idle": "2025-05-26T17:17:42.975067Z",
     "shell.execute_reply": "2025-05-26T17:17:42.974304Z",
     "shell.execute_reply.started": "2025-05-26T17:17:20.490549Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Carga los splits y los convierte en tensores de pytorch para crear los Dataloaders\n",
    "\n",
    "DATA_DIR=\"splits\"\n",
    "\n",
    "X_train = np.load(os.path.join(DATA_DIR, \"X_train.npy\"))\n",
    "X_test = np.load(os.path.join(DATA_DIR, \"X_test.npy\"))\n",
    "y_train = np.load(os.path.join(DATA_DIR, \"y_train.npy\"))\n",
    "y_test = np.load(os.path.join(DATA_DIR, \"y_test.npy\"))\n",
    "class_to_idx = np.load(os.path.join(DATA_DIR, \"class_to_idx.npy\"), allow_pickle=True).item()\n",
    "\n",
    "# Convertir a tensores PyTorch\n",
    "X_train_tensor = torch.tensor(X_train).permute(0, 3, 1, 2).float()  # [N, C, H, W]\n",
    "X_test_tensor = torch.tensor(X_test).permute(0, 3, 1, 2).float()\n",
    "y_train_tensor = torch.tensor(y_train).long()\n",
    "y_test_tensor = torch.tensor(y_test).long()\n",
    "\n",
    "# Crear Datasets y DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitectura paper original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T17:18:04.127880Z",
     "iopub.status.busy": "2025-05-26T17:18:04.127220Z",
     "iopub.status.idle": "2025-05-26T17:18:04.133081Z",
     "shell.execute_reply": "2025-05-26T17:18:04.132417Z",
     "shell.execute_reply.started": "2025-05-26T17:18:04.127854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CameraConvNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CameraConvNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=7),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(128, 512, kernel_size=7),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(512, 2048, kernel_size=6),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T17:18:09.517082Z",
     "iopub.status.busy": "2025-05-26T17:18:09.516615Z",
     "iopub.status.idle": "2025-05-26T18:40:17.956673Z",
     "shell.execute_reply": "2025-05-26T18:40:17.955729Z",
     "shell.execute_reply.started": "2025-05-26T17:18:09.517058Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = len(class_to_idx)\n",
    "model = CameraConvNet(num_classes).to(device)\n",
    "\n",
    "# Ellos usan Softmax y LogLoss pero chat dice que es lo mismo\n",
    "# que usar CrossEntropy, mire y creo que tiene sentido \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Estoy mirando el paper pero no dice nada del learning rate \n",
    "# solo dice: tasa de aprendizaje decreciente \n",
    "\n",
    "# el optimizador como tal no dicen cual usan pero en la seccion 2. BACKGROUND ON CONVOLUTIONAL NETWORKS\n",
    "# dicen que es normal usar \"gradient descent\" entonces SGD?\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 200 #El paper dice que son 200 \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {running_loss/len(train_loader):.4f} - Accuracy: {correct/total:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5293423,
     "sourceId": 8802148,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7513583,
     "sourceId": 11951092,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
